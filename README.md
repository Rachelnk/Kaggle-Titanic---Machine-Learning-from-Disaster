# Kaggle-Titanic---Machine-Learning-from-Disaster 
## Background
- The sinking of the Titanic is one of the most infamous shipwrecks in history.
- On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.
- While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.

## Objectives
- The main objetive of this project is:
  1. Use machine learning to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).
  
## Methodology:
The following steps taken:
1. Clean and prepare data for analysis using Pandas.
2. Perform data analysis to uncover insights and feature engineering to create new features to improve ML model performance.
3. Train, test and evaluate the models i.e. LogisticRegression, RandomForestClassifier, KNeighborsClassifier, GaussianNB, Support Vector Classifier (SVC). Select the model that offers the best prediction.

## Model Scores

![Titanic2](https://github.com/user-attachments/assets/fddfb900-87df-4d9e-a1a9-12e495cea2b1)
![Titanic1](https://github.com/user-attachments/assets/bda6c467-6cc6-4077-93c7-7889f6bee2be)

## Conclusion
- Logistic Regression Model has the highest score, therefore the best predictive model.
